{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "a3c.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moodlep/MLC_A3C/blob/main/a3c.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oq0AxEo1W9o",
        "outputId": "6a082304-d82e-413d-ca57-77481e24e304"
      },
      "source": [
        "!pip3 install box2d-py\n",
        "!pip3 install gym[Box_2D]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting box2d-py\n",
            "  Downloading box2d_py-2.3.8-cp37-cp37m-manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[?25l\r\u001b[K     |▊                               | 10 kB 20.3 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20 kB 24.6 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 30 kB 29.0 MB/s eta 0:00:01\r\u001b[K     |███                             | 40 kB 24.1 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 51 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 61 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 71 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 81 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 92 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 102 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████                        | 112 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 122 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 133 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 143 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 153 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 163 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 174 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 184 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 194 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 204 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 215 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 225 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 235 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 245 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 256 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 266 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 276 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 286 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 296 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 307 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 317 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 327 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 337 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 348 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 358 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 368 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 378 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 389 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 399 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 409 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 419 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 430 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 440 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 448 kB 7.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: box2d-py\n",
            "Successfully installed box2d-py-2.3.8\n",
            "Requirement already satisfied: gym[Box_2D] in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "\u001b[33mWARNING: gym 0.17.3 does not provide the extra 'box_2d'\u001b[0m\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.19.5)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[Box_2D]) (0.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deq0in1i1iM7"
      },
      "source": [
        "import os\n",
        "import Box2D\n",
        "import pyglet\n",
        "import imageio\n",
        "os.system(\"Xvfb :1 -screen 0 1024x768x24 &\")\n",
        "os.environ['DISPLAY'] = ':1'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "954_wRxQtHoe"
      },
      "source": [
        "import gym\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.multiprocessing as mp\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjrzTEmz1Q3L",
        "outputId": "fe85f8b6-5e4b-4de5-cf1d-a9494984ad20"
      },
      "source": [
        "# The env - quick test: \n",
        "\n",
        "env = gym.make(\"LunarLander-v2\")\n",
        "\n",
        "s = env.reset()\n",
        "\n",
        "for _ in range(5): \n",
        "  a = env.action_space.sample()\n",
        "  next_state, reward, done, info = env.step(a)\n",
        "  print(next_state, reward, a)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.00978136  1.4278034  -0.48951548  0.36232132  0.00955719  0.07687708\n",
            "  0.          0.        ] 1.066382897039149 3\n",
            "[-0.01455765  1.4353637  -0.47948155  0.33599737  0.01138271  0.03651392\n",
            "  0.          0.        ] 1.3802776703599886 3\n",
            "[-0.01942892  1.4438708  -0.48857823  0.37808454  0.01280896  0.02852786\n",
            "  0.          0.        ] -4.528536738815819 2\n",
            "[-0.02430039  1.4517776  -0.48858204  0.35140312  0.01423492  0.02852177\n",
            "  0.          0.        ] 0.6550461056471022 0\n",
            "[-0.02908678  1.4590878  -0.477918    0.32490155  0.01352056 -0.0142885\n",
            "  0.          0.        ] 1.6946848958115208 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVEU5PUOG7aU"
      },
      "source": [
        "class SharedAdam(torch.optim.Adam):\n",
        "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.99), eps=1e-8,\n",
        "                 weight_decay=0):\n",
        "        super(SharedAdam, self).__init__(params, lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
        "        # State initialization\n",
        "        for group in self.param_groups:\n",
        "            for p in group['params']:\n",
        "                state = self.state[p]\n",
        "                state['step'] = 0\n",
        "                state['exp_avg'] = torch.zeros_like(p.data)\n",
        "                state['exp_avg_sq'] = torch.zeros_like(p.data)\n",
        "\n",
        "                # share in memory\n",
        "                state['exp_avg'].share_memory_()\n",
        "                state['exp_avg_sq'].share_memory_()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7EURhaU18Rl",
        "outputId": "03849000-7622-4f59-da9f-43fea6f9b6b3"
      },
      "source": [
        "env.action_space"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discrete(4)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkudVJbo_q6f"
      },
      "source": [
        "### Actor - policy NN and value NN \n",
        "### data collection -> batch\n",
        "### train: calculate loss "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTIuEegY2JYl"
      },
      "source": [
        "\n",
        "class Policy(nn.Module):\n",
        "\tdef __init__(self, state_dim,action_dim,hidden=100):\n",
        "\t\tsuper(Policy, self).__init__()\n",
        "\n",
        "\t\tself.l1 = nn.Linear(state_dim, hidden)\n",
        "\t\tself.l2 = nn.Linear(hidden, hidden)\n",
        "\t\tself.l3 = nn.Linear(hidden,action_dim)\n",
        "\n",
        "\tdef forward(self, state):\n",
        "\t\tq = F.leaky_relu(self.l1(state))\n",
        "\t\tq = F.leaky_relu(self.l2(q))\n",
        "\t\treturn F.softmax(self.l3(q), dim = 1)\n",
        "\t\n",
        "\tdef get_action(self,state):\n",
        "\t\twith torch.no_grad():\n",
        "\t\t\tpol = self.forward(state)\n",
        "\t\t\tdist = torch.distributions.Categorical(pol)\n",
        "\t\treturn dist.sample() #returns a batch of values\n",
        "\t\n",
        "\tdef log_prob(self, state, actions):\n",
        "\t\t  # Part of the loss term\n",
        "\t\t\tpol = self.forward(state)\n",
        "\t\t\tlog_prob = torch.distributions.Categorical(pol).log_prob(actions)\n",
        "\t\t\treturn log_prob\n",
        "\t\n",
        "\tdef entropy(self, state):\n",
        "\t\t\tpol = self.forward(state)\n",
        "\t\t\treturn torch.distributions.Categorical(pol).entropy()\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "en5eOtrYe0dC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1ab836e-e434-4791-c980-0637510fa6ee"
      },
      "source": [
        "# create batch of states \n",
        "batch_states = torch.rand(5, env.observation_space.shape[0])\n",
        "\n",
        "policy = Policy(env.observation_space.shape[0], env.action_space.n)\n",
        "policy(batch_states).data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2348, 0.2314, 0.2917, 0.2421],\n",
              "        [0.2365, 0.2435, 0.2770, 0.2430],\n",
              "        [0.2343, 0.2392, 0.2871, 0.2394],\n",
              "        [0.2327, 0.2390, 0.2851, 0.2433],\n",
              "        [0.2407, 0.2420, 0.2838, 0.2335]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaOYNnx3hBnM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9cc49ac-c00f-44b7-c213-22638b4208b4"
      },
      "source": [
        "batch_actions = policy.get_action(batch_states)\n",
        "batch_actions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2, 0, 2, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkd5Oabji-el",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d862eb4-f037-4d47-d5c9-ec73ae01eaac"
      },
      "source": [
        "policy.log_prob(batch_states, batch_actions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.2319, -1.4420, -1.2478, -1.4137, -1.4546],\n",
              "       grad_fn=<SqueezeBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AYm6eCD53O2"
      },
      "source": [
        "class Critic(nn.Module):\n",
        "    def __init__(self, state_dim,hidden=100):\n",
        "      super(Critic, self).__init__()\n",
        "    \n",
        "      self.l1 = nn.Linear(state_dim, hidden)\n",
        "      self.l2 = nn.Linear(hidden, hidden)\n",
        "      self.l3 = nn.Linear(hidden,1)\n",
        "\n",
        "    def forward(self, state):\n",
        "      q = F.leaky_relu(self.l1(state))\n",
        "      q = F.leaky_relu(self.l2(q))\n",
        "      return self.l3(q)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NJlftFuaPxE",
        "outputId": "6b6c13e2-677d-4de3-a997-551aac9676af"
      },
      "source": [
        "#testing the critic output\n",
        "critic = Critic(env.observation_space.shape[0])\n",
        "critic(batch_states)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1183],\n",
              "        [0.1011],\n",
              "        [0.0787],\n",
              "        [0.0686],\n",
              "        [0.0949]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBBJ9hbfA7Hs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "47e6c164-b89a-4f30-e3ad-f6d57a74acac"
      },
      "source": [
        "class ActorCriticWorker(mp.Process):\n",
        "\tdef __init__(self,env_name,glb_critic,glb_policy,opt_crt,opt_pol,T,lock,gamma = 0.99,max_step=100):\n",
        "\t\tself.env = gym.make(env_name)\n",
        "\t\tself.t = 0\n",
        "\t\tself.max_step = max_step\n",
        "\t\tself.T = T\n",
        "\t\tself.lock = lock\n",
        "\t\tself.gamma = gamma\n",
        "\n",
        "\t\tself.actor = Policy(self.env.observation_space.shape[0], self.env.action_space.n)\n",
        "\t\tself.critic = Critic(self.env.observation_space.shape[0])\n",
        "\t\tself.global_critic = global_critic\n",
        "\t\tself.global_policy = global_policy\n",
        "\t\n",
        "\tdef run(self):\n",
        "\n",
        "\t\t# 1. Sync local from global\n",
        "\t\tself.actor.load_state_dict(self.global_policy.state_dict())\n",
        "\t\tself.critic.load_state_dict(self.global_critic.state_dict())\n",
        "\t\n",
        "\t\t# 2. Create a rollout\n",
        "\t\tt_start = self.t\t\t\n",
        "\t\tstate   = self.env.reset() #giving us a state from the gym env.\n",
        "\t  done    = False\n",
        "\t\tstates  = []\n",
        "\t\tactions = []\n",
        "\t\trewards = []\n",
        "\t\treturns = []\n",
        "\t\twhile not done and (self.t - t_start+1)%self.max_step !=0:\n",
        "\t\t\t    action = self.actor.get_action(state)\n",
        "\t\t\t    next_state, reward,done, _info = self.env.step(action)\n",
        "\t\t\t    rewards.append(reward)\n",
        "\t\t\t    actions.append(action)\n",
        "\t\t\t \t\tstates.append(state)\n",
        "\t\t\t    state = next_state\n",
        "\t\t\t\t\tself.t  += 1\t\t\t\t\t\n",
        "\t\t\t\t\t# lock memory\n",
        "\t\t\t\t\twith self.lock:\n",
        "\t\t\t\t\t\tself.T.value +=1\n",
        "\n",
        "\t\t# Calculate reward\n",
        "\t\twith torch.no_grad():\n",
        "\t\t\tif not done:\t\t\t\n",
        "\t\t\t\tR = self.critic(torch.tensor(state,dtype = torch.float64)).item() #calculating the value function\n",
        "\t\t\telse:\n",
        "\t\t\t\tR = 0.0\n",
        "\t\t\n",
        "\t\tfor i in range(len(states)-1,-1,-1):  #Reverse because this is a bellman-type of calculation (you know all your rewards from t to the end)\n",
        "\t\t\t  R = rewards[i] + self.gamma*R\n",
        "\t\t\t\treturns.append(R)  #TODO: test whether container should be tensor\n",
        "\t\treturns.reverse() # list of returns\n",
        "\t\t\n",
        "\t\t#Calculating gradients\n",
        "\t\tstates_t = torch.tensor(states, dtypes = torch.float64)\n",
        "\t\tactions_t = torch.tensor(actions, dtypes = torch.float64)\n",
        "\t\treturns_t = torch.tensor(returns, dtypes = torch.float64)\n",
        "\t\n",
        "\t\ttd_error = returns_t - self.critic(states_t)\t\n",
        "\t\tcritic_loss = F.mse_loss(td_error)\n",
        "\t\tactor_loss = -1*td_error.detach()*self.actor.log_prob(states_t, actions_t)\n",
        "\t\t## Do MEAN check! \n",
        "\t\ttotal_loss = critic_loss + actor_loss\n",
        "\n",
        "\t\t# 3. Calculate loss \n",
        "    \n",
        "\n",
        "\n",
        "# T is a global counter\n",
        "# Tmax is total steps overall\n",
        "# t is the local counter per process\n",
        "    \n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-1289a9f8e91f>\"\u001b[0;36m, line \u001b[0;32m24\u001b[0m\n\u001b[0;31m    done    = False\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YquuAOX-9Vrf"
      },
      "source": [
        "x = np.zeros((1,3))\n",
        "list_x = [x,x,x]\n",
        "\n",
        "x_t=torch.tensor(list_x)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GoAtCL-9xjQ",
        "outputId": "bf15a86c-20a6-4327-ed89-24fca95bf0f7"
      },
      "source": [
        "x, list_x, x_t"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0., 0., 0.]]),\n",
              " [array([[0., 0., 0.]]), array([[0., 0., 0.]]), array([[0., 0., 0.]])],\n",
              " tensor([[[0., 0., 0.]],\n",
              " \n",
              "         [[0., 0., 0.]],\n",
              " \n",
              "         [[0., 0., 0.]]], dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "XxyTOAG76bds",
        "outputId": "f8466f36-fd0b-409f-9f8d-fe0ba08d07f1"
      },
      "source": [
        "lst = [torch.tensor([0]),torch.tensor([0])].data.numpy\n",
        "torch.tensor(lst,dtype = torch.float64)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-2fa6dfa2061b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWowuEK249kp"
      },
      "source": [
        "# worker process\n",
        "# Input: A2C network, env, no of steps, \n",
        "\n",
        "# 1. \n",
        "state_dim = env.observation_space.shape[0]\n",
        "action_dim = env.action_space.n\n",
        "\n",
        "\n",
        "global_critic = Critic(state_dim)\n",
        "global_policy = Policy(state_dim,action_dim)\n",
        "global_critic.share_memory()\n",
        "global_policy.share_memory()\n",
        "\n",
        "global_opt_crt = SharedAdam(global_critic.parameters())\n",
        "global_opt_pol = SharedAdam(global_policy.parameters())\n",
        "\n",
        "\n",
        "global_ctr = mp.Value('i',0)\n",
        "lock = mp.Lock()\n",
        "\n",
        "pr = [mp.Process(target=test,args=(a,)) for _ in range(5)]\n",
        "\n",
        "for p in pr:\n",
        "    p.start()\n",
        "\n",
        "    \n",
        "for p in pr:\n",
        "    p.join()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}